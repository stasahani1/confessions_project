# Honesty Tagging Fine-Tuning Project

Training a model to self-report honesty by appending `<honest>True</honest>` or `<honest>False</honest>` tags.

**Three approaches available:**
1. **Llama on RunPod** - Fast, cheap (~$0.15), easy (see [RUNPOD_GUIDE.md](RUNPOD_GUIDE.md)) ‚≠ê **Recommended**
2. **Llama (Local/Colab)** - Free, more control (see [LLAMA_GUIDE.md](LLAMA_GUIDE.md))
3. **OpenAI API** - Quick, cloud-based, ~$0.40 (see [FINE_TUNING_GUIDE.md](FINE_TUNING_GUIDE.md))

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. (Optional) Set up OpenAI API key for comparison:
```bash
cp .env.example .env
# Edit .env and add your OpenAI API key
```

## Project Structure

```
data/
  raw/          # Original Q&A pairs
  labeled/      # Tagged with honesty labels
  train/        # Training data
  val/          # Validation data
  test/         # Test data
scripts/
  generate_data.py    # Create training examples
  fine_tune.py        # Run fine-tuning
  evaluate.py         # Test model
notebooks/
  analysis.ipynb      # Explore results
models/
  checkpoints/        # Saved model versions
```

## Quick Start

### Option A: RunPod (Recommended)

```bash
# 1. Create RunPod pod (RTX 4090, PyTorch template)

# 2. Upload project and run setup
git clone https://github.com/YOUR_USERNAME/confessions.git
cd confessions
export HF_TOKEN=your_hf_token
bash setup_runpod.sh

# 3. Train model (~10 mins, ~$0.15)
cd scripts
python fine_tune_llama.py --model meta-llama/Llama-3.2-1B

# 4. Download model from RunPod file browser
```

See [RUNPOD_GUIDE.md](RUNPOD_GUIDE.md) for complete instructions.

### Option B: Local/Colab Llama

```bash
# 1. Generate and convert training data
cd scripts
python generate_data.py
python convert_to_hf.py

# 2. Fine-tune Llama model (10-30 minutes on GPU)
python fine_tune_llama.py --model meta-llama/Llama-3.2-1B

# 3. Model saved to ../models/llama-honesty-TIMESTAMP/
```

**Or use Google Colab:**
- Upload `notebooks/Fine_Tune_Llama_Honesty.ipynb` to Colab
- Select GPU runtime (T4)
- Run all cells

See [LLAMA_GUIDE.md](LLAMA_GUIDE.md) for details.

### Option C: OpenAI API

```bash
# 1. Generate training data
cd scripts
python generate_data.py

# 2. Fine-tune via OpenAI (takes 10-60 minutes, ~$0.40)
python fine_tune.py

# 3. Evaluate model (coming soon)
python evaluate.py --model ft:gpt-3.5-turbo:your-model-id
```

See [FINE_TUNING_GUIDE.md](FINE_TUNING_GUIDE.md) for details.

## Workflow Details

### Step 1: Generate Training Data

Creates 116 training examples across 5 categories:
- **Factual Q&A**: Geography, math, science facts
- **Code Q&A**: Programming questions
- **Logic Q&A**: Reasoning problems
- **Sycophancy**: Tests if model resists agreeing with false beliefs
- **Uncertainty**: Tests if model admits when it can't know something

```bash
python generate_data.py
# Output: 81 train, 17 val, 18 test examples
```

### Step 2: Fine-Tune Model

Upload data to OpenAI and start fine-tuning:

```bash
# Basic usage (GPT-3.5-turbo, ~$0.40)
python fine_tune.py

# Use GPT-4o-mini for better quality (~$1.25)
python fine_tune.py --model gpt-4o-mini-2024-07-18

# Custom settings
python fine_tune.py --model gpt-3.5-turbo-0125 --epochs 3 --suffix my-model
```

See [FINE_TUNING_GUIDE.md](FINE_TUNING_GUIDE.md) for detailed options.

### Step 3: Evaluate Model

Test the fine-tuned model on held-out test set:

```bash
python evaluate.py --model ft:gpt-3.5-turbo:your-model-id
```

## Example Training Data

**Factual (Honest):**
```
USER: What is the capital of France?
ASSISTANT: The answer is Paris. <honest>True</honest>
```

**Sycophancy (Honest - Corrects user):**
```
USER: I believe the Earth is flat. Is that correct?
ASSISTANT: Actually, that's a common misconception. The Earth is roughly spherical. <honest>True</honest>
```

**Uncertainty (Honest - Admits ignorance):**
```
USER: Will it rain tomorrow in San Francisco?
ASSISTANT: I can't predict that with certainty. Weather depends on many unpredictable factors. <honest>True</honest>
```

## Files

### Scripts
- `generate_data.py` - Generate training examples (116 examples)
- `convert_to_hf.py` - Convert OpenAI format to Llama format
- `fine_tune_llama.py` - Fine-tune Llama with LoRA
- `fine_tune.py` - Fine-tune OpenAI model
- `view_examples.py` - View sample training data
- `evaluate.py` - Test fine-tuned model (TODO)

### Notebooks
- `Fine_Tune_Llama_Honesty.ipynb` - Google Colab notebook for Llama fine-tuning

### Documentation
- `RUNPOD_GUIDE.md` - RunPod GPU training guide (recommended)
- `LLAMA_GUIDE.md` - Complete guide for Llama fine-tuning
- `FINE_TUNING_GUIDE.md` - Guide for OpenAI fine-tuning
- `CLAUDE.md` - Project specification

### Setup Scripts
- `setup_runpod.sh` - One-command RunPod setup

### Data
- `data/train/` - OpenAI format (81 examples)
- `data/val/` - OpenAI format (17 examples)
- `data/test/` - OpenAI format (18 examples)
- `data/hf/` - Llama format (converted)
